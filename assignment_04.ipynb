{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec859233",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Initialize Otter\n",
    "import otter\n",
    "grader = otter.Notebook(\"assignment_04.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b04232b",
   "metadata": {},
   "source": [
    "# Resolving Git Conflicts\n",
    "\n",
    "In the previous assignment, our emphasis was on utilizing terminal commands to enhance flexibility and versatility while executing Git commands. However, in this assignment, we will also concentrate on learning how to use the Jupyter Lab IDE since it provides a convenient graphical (but slightly less flexible) approach to Git change tracking. Jupyter Lab IDE, in particular, is ideal for resolving Git conflicts and you will have the opportunity to practice this skill in this assignment. To evaluate your grasp of effective version control, you will be be asked several questions to assess your understanding of the material."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16a50ab",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "## Submission instructions\n",
    "\n",
    "<p>You receive marks for submitting your lab correctly, please follow these instructions:</p>\n",
    "\n",
    "<ul>\n",
    "  <!-- <li>Make at least three commits.</li>-->\n",
    "  <li>Export to HTML via <code>File -> Save and export notebook as... -> HTML</code> and upload the HTML file to Canvas.</li>\n",
    "    <ul>\n",
    "      <li>Before submitting, make sure you restart the kernel and rerun all cells.</li>\n",
    "    </ul>\n",
    "  <li>Don't change any variable names that are given to you, don't move cells around, and don't include any code to install packages in the notebook.</li>\n",
    "  </li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b2b7d2",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## Recap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be3ac79b",
   "metadata": {},
   "source": [
    "Before we start, let's make sure we are familiar with the terminal \"alternatives\" to the following commands in Jupyter Lab IDE:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b69660",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 0a\n",
    "    \n",
    "Match the Jupyter Lab IDE interface component shown in the figure with the equivalent Git command\n",
    "\n",
    "<img src=\"images/Picture1a.png\" width=40% >\n",
    "\n",
    "A) `git add <file>`    \n",
    "B) `git commit -m \"message\"`  \n",
    "C) `git status`    \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f17947e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q0a = \"C\"\n",
    "q0a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3736d02c",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0a</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q0a results: All test cases passed!"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de0a391",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 0b\n",
    "    \n",
    "Match the Jupyter Lab IDE interface component shown in the figure with the equivalent Git command\n",
    "\n",
    "<img src=\"images/Picture1b.png\" width=40% >\n",
    "\n",
    "A) `git log --oneline`    \n",
    "B) `git history`  \n",
    "C) `git commit -m \"message\"`    \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c314e9f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q0b = \"a\"\n",
    "q0b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1a22af4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0b</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q0b results: All test cases passed!"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5b1002",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 0c\n",
    "    \n",
    "Match the Jupyter Lab IDE interface component shown in the figure with the equivalent Git command\n",
    "\n",
    "<img src=\"images/Picture1c.png\" width=30% >\n",
    "\n",
    "A) `git status`    \n",
    "B) `git commit -m \"message\"`  \n",
    "C) `git comment`  \n",
    "D) `git add <file>`    \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d26afb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q0c = \"B\"\n",
    "q0c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31a7fe13",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0c</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q0c results: All test cases passed!"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2986b5b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 0d\n",
    "    \n",
    "Match the Jupyter Lab IDE interface component shown in the figure with the equivalent Git command\n",
    "\n",
    "<img src=\"images/Picture1d.png\" width=30% >\n",
    "\n",
    "A) `git reset --hard <hash>`    \n",
    "B) `git revert <hash>`   \n",
    "C) `git log --oneline`    \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff29e08e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'a'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q0d = \"a\"\n",
    "q0d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30311164",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0d</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q0d results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d610c9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 0e\n",
    "    \n",
    "Match the Jupyter Lab IDE interface component shown in the figure with the equivalent Git command\n",
    "\n",
    "<img src=\"images/Picture1e.png\" width=40% >\n",
    "\n",
    "A) `git reset --hard <hash>`    \n",
    "B) `git log --oneline`    \n",
    "C) `git revert <hash>`     \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd3117f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q0e = \"c\"\n",
    "q0e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c003b20",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q0e</pre></strong> passed! 🌟</p>"
      ],
      "text/plain": [
       "q0e results: All test cases passed!"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q0e\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96af3bfc",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Part I: Viewing the changes\n",
    "\n",
    "**Importnat:** Before you continue working on your `recipe` repo, always check `git status` to make sure that there is no unsaved or uncommitted changes in your repo. After you type a command, you should see message something like that:  `Your branch is up to date with 'origin/main'` and `nothing to commit, working tree clean`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab8e8bc6",
   "metadata": {},
   "source": [
    "**Step 1.**  Let's explore git history commands.\n",
    "\n",
    "If you haven't yet, please try now `git log` in your terminal to check the history of your `recipe` folder.\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "If the <code>git log</code> output is too long to fit in your terminal window, you will see the last part of the output and a message that says <code>:</code> to indicate that there is more output to display. You can then press the spacebar to scroll through the output one screen at a time, or press Enter to scroll through it one line at a time. If you reached the end of the output you will see a line <code>(END)</code>. In order to exit, press <code>q</code></details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506362ec",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 1a\n",
    "    \n",
    "Which of the following statements are TRUE about command `git log`?\n",
    "\n",
    "A)\tWe can browse the development and access each state that we have committed  \n",
    "B)\tThe long hashes uniquely label a state of the code  \n",
    "C)\tOutput is in chronological order with newest commits on top  \n",
    "D)\tOutput is in chronological order with oldest commits on top  \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e48c7de8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABC'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q1a = \"ABC\"\n",
    "q1a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5dd4bf6b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1a</pre></strong> passed! 🚀</p>"
      ],
      "text/plain": [
       "q1a results: All test cases passed!"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b5b60",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 1b\n",
    "\n",
    "Explore what these commands do and match them with the correct explanation in the table below:\n",
    "\n",
    "- `git log --stat`  <br>    \n",
    "- `git log --oneline`\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "Note, that you may need to press <code>q</code> to exit the command. \n",
    "</details>\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td> <b>Command:</b></td>\n",
    "<td> <b>Match the command to what they do:</b></td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> \n",
    "\n",
    "1. `git log --stat`  \n",
    "2. `git log --oneline`\n",
    "\n",
    "</td>\n",
    "<td> \n",
    "     \n",
    "A. Displays a summarized view of the commit history with only the first line of each commit message. The Git hash for each commit is displayed as a short, unique identifier composed of 7 characters.   \n",
    "B. Displays the commit history with a detailed list of the files that were changed in each commit. The Git hash for each commit is displayed as a 40-character hexadecimal string, which serves as a unique identifier for the commit.  \n",
    "C. Displays the commit history with a detailed view of the changes made to each file in each commit. The Git hash for each commit is displayed as a 40-character hexadecimal string, which serves as a unique identifier for the commit.\n",
    "\n",
    "</td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b5449aaf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BA'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q1b = \"BA\"\n",
    "q1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e8ee19f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1b</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "q1b results: All test cases passed!"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc741094",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 1c\n",
    "\n",
    "Below, you can see student's output of the `git log --oneline`. Which of the following statements are TRUE about the output?\n",
    "\n",
    "<img src=\"images/Picture3.png\" width=50% >\n",
    "\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "To decide which commit is older, you can use <code>git log</code> command to figure out how the order of hashes in your <code>recipe</code> repo is correlated with <code>git --oneline</code> output \n",
    "</details>\n",
    "</br>\n",
    "\n",
    "A)\t`ac2e05f` can be a short form of <code>f57cde96f132fe41c226a6ab4f30040c1<b>ac2e05f</b></code>   \n",
    "B)\t`ac2e05f` can be a short form of <code><b>ac2e05f</b>f57cde96f132fe41c226a6ab4f30040c1</code>   \n",
    "C)\t`ac2e05f` is the newer than `5567d20`  \n",
    "D)\t`ac2e05f` is older than `5567d20`  \n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "cfecb05c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BD'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q1c = \"BD\"\n",
    "q1c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c6ad1c4b",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1c</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q1c results: All test cases passed!"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36744719",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "**Step 2.** Exploring the differences with git\n",
    "\n",
    "Before answering the next question, let's continue working on our local `recipe` repo from last assignment and modify the `ingredients.md` file. \n",
    "\n",
    "1. Add `Enjoy my recipe!` as the last line of your document \n",
    "2. Add `Let's begin!` as the first line of your document. \n",
    "3. After you done, save the document but **do not** stage the changes yet (**do not** `git add`) and try `git diff ingredients.md` and explore the output.\n",
    "4. Once you finished, stage,commit the changes, push to the remote, and answer the question below\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018fc4dd",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 2a\n",
    " \n",
    "A student was working on changes to their `README.md` file. Based on the output of `git diff`, can you identify what changes have been made to a file? Select all that applies.\n",
    "\n",
    "<img src=\"images/Picture2.png\" width=50% >\n",
    "\n",
    "A) word \"Title:\" was added to the line with \"My Favourite recipe\" in it      \n",
    "B) word \"Title:\" was removed from the line with \"My Favourite recipe\" in it     \n",
    "C) `####` was added to the file  \n",
    "D) `####` was removed from the file  \n",
    "E) \"Enjoy my recipe!\" was added to the file  \n",
    "F) \"Enjoy my recipe!\" was removed from the file   \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "af74aabc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ADE'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q2a = \"ADE\"\n",
    "q2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d2a25d26",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2a</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q2a results: All test cases passed!"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a8b94e",
   "metadata": {},
   "source": [
    "In addition, try to inspect differences between commit hashes with `git diff <hash1> <hash2>`. You can choose any two hashes that you want from your list of `git --log` or `git --oneline`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caaed87",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 2b\n",
    " \n",
    "Explore commit history of the project Glosario on GitHub (https://github.com/carpentries/glosario).\n",
    "Which of the following commands would compare the commit `aaa99e8` with the commit `03b68de`? Assume you have clonned the project to your local computer. \n",
    "\n",
    "A) Navigating to this URL `https://github.com/carpentries/glosario/compare/03b68de aaa99e8`    \n",
    "B) Navigating to this URL `https://github.com/carpentries/glosario/compare/03b68de..aaa99e8`   \n",
    "C) The following git shell command: `git diff 03b68de..aaa99e8`    \n",
    "D) The following git shell command: `git diff 03b68de aaa99e8` \n",
    " \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "19b267b1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BD'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q2b = \"BD\"\n",
    "q2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f57cb609",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2b</pre></strong> passed! 🚀</p>"
      ],
      "text/plain": [
       "q2b results: All test cases passed!"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba5747b",
   "metadata": {},
   "source": [
    "## Part II: Ignoring files and paths with `.gitignore`\n",
    "\n",
    "`.gitignore` is a file used in Git version control systems to specify files and directories that should be ignored and not tracked by Git. This is useful for a number of reasons:\n",
    "\n",
    "1. Excluding files or directories that contain sensitive information, such as passwords or secret keys, from being tracked and committed to a repository.\n",
    "2. Ignoring files generated by the build process, e.g., `.ipynb_checkpoints` is a folder that is automatically generated by Jupyter Notebook when you create or edit a notebook. It contains checkpoint files that Jupyter Notebook creates as a backup of your notebook's state.\n",
    "3. Preventing version control clutter by ignoring files that are temporary, backup or log files.\n",
    "\n",
    "\n",
    "By using a `.gitignore` file, you can keep your version control history clean, reduce repository size, and avoid potential security risks by not tracking sensitive information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61c5bc",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 3a\n",
    "    \n",
    "What does it mean to have an untracked file in your repository? Select the correct option. \n",
    "\n",
    "A) It is a file that you have made changes to but not yet committed   \n",
    "B) It is a new file added to a Git repository that has not been staged yet   \n",
    "C) It is a file that has not been modified since you started to work in the repository\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d5ba7968",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q3a = \"B\"\n",
    "q3a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9154cbbf",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3a</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q3a results: All test cases passed!"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e338a9ce",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 3b\n",
    "\n",
    "What is the recommended approach for managing automatically generated files in a project?\n",
    "\n",
    "A) Add them all to version control and track changes over time.   \n",
    "B) Do not add them to version control and regenerate them as needed during the build process.\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3d86efd5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q3b = \"B\"\n",
    "q3b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "15e14632",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3b</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "q3b results: All test cases passed!"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119f6d1a",
   "metadata": {},
   "source": [
    "----\n",
    "**Step 3.** Make sure your local repo is up-to-date with the remote repo (and vice versa). Now go to Github.com and create a `.gitignore` file in your `recipe` repository.\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "If you forgot how to create a new files on GitHub, check the Assignment 3 where we created <code>ingredients.md</code> file. Same steps should be followed here but the file should be named <code>.gitignore</code>.\n",
    "</details>\n",
    "</br>\n",
    "\n",
    "Add the following file to your `.gitignore`:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4103c423",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "**/*.log\n",
    ".DS_Store\n",
    ".ipynb_checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f84401a9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 3c\n",
    "    \n",
    "True or False? When you create a new repository on Github.com you have the\n",
    "option include a `.gitignore` template file tailored to the programming language of your choice.\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "Try creating a new repository on GitHub to explore what could be the correct\n",
    "answer to this question\n",
    "</details>\n",
    "</br>\n",
    "\n",
    "A) True  \n",
    "B) False\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "304b20b9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q3c = \"A\"\n",
    "q3c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "55c2d5f1",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3c</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "q3c results: All test cases passed!"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "122a0b2f",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "## Part III: Undoing the changes\n",
    "\n",
    "Let's imagine that you're in a scenario where you have committed some changes to your project that you then realized that you want to undo them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae2ffa9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "### Question 4a\n",
    "    \n",
    "Which of these commands is(are) the most appropriate to use for undoing the changes you made in a commit?\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "make some changes to your repo, stage and commit them. Then try all the commands in your repository and check the project history before answering the question\n",
    "</details>\n",
    "</br>\n",
    "\n",
    "A) Revert your changes via `git revert`  \n",
    "B) Hard reset your changes via `git reset --hard`  \n",
    "C) Commit your changes via `git commit`  \n",
    "D) Add your saved changes to the staging area via `git add`\n",
    "\n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5027df58",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AB'"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q4a = \"AB\"\n",
    "q4a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c874883",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4a</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q4a results: All test cases passed!"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ac4dca",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Step 4**  Another day at the office. Open your `ingredients.md` file and add you phone number at the end of the document (you can create a fake one). Stage and commit the changes (but **don't** push!). Use \"phone number added\" as your commit message."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62948a7",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 4b\n",
    "\n",
    "After committing your changes, you realized that you have accidentally included in the commit one important personal file with sensitive information! \n",
    "\n",
    "What of the following strategies would you use to solve this problem? Think carefully, you don't want to keep that commit in your project history!\n",
    "\n",
    "A) You can run `git reset --hard <commit hash>` to the previous commit.  \n",
    "B) You can run `git revert <hash>` to the previous commit.  \n",
    "C) You can delete the line from your file and make a new commit \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9a74dc4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q4b = \"A\"\n",
    "q4b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "e3686423",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4b</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "q4b results: All test cases passed!"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9659f492",
   "metadata": {},
   "source": [
    "Perform the action from the question above to remove sensitive informtaion. Double check that your commit was removed from the history."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c73cb3e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 4c\n",
    "\n",
    "Let's imagine that you're in a scenario where you have committed some changes to your project that you then realized that you want to undo. Which of these commands is the most appropriate to use for undoing the changes you made in a commit (especially if you working with other collaborators)?\n",
    "\n",
    "A) Add your saved changes to the staging area via `git add`    \n",
    "B) Commit your changes via `git commit`    \n",
    "C) Hard reset your changes via `git reset --hard`    \n",
    "D) Revert your changes via `git revert`   \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "600b9c50",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q4c = \"D\"\n",
    "q4c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "593bb9a4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4c</pre></strong> passed! 🙌</p>"
      ],
      "text/plain": [
       "q4c results: All test cases passed!"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4c\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa12639c",
   "metadata": {},
   "source": [
    "## Part IV: Resolving merge conflict \n",
    "\n",
    "Now we're switching gears to assess you on the remaining parts of this chapter.\n",
    "\n",
    "**Before starting this part, make sure that your local and remote repo are synced (check `git status`). If you made any changes to your local repo, make sure you `push` those changes to the remote.**\n",
    "\n",
    "To summarize, the diagram below illustrate possible scenarios that can happen when you pull/push changes between local (repo on your PC) and remote (repo on GitHub) repositories:\n",
    "\n",
    "\n",
    "<img src=\"images/Picture5.png\" width=80% >\n",
    "\n",
    "- **Scenario 1 & 2** In Assignment 3 we performed the first 2 options: changing local files and sending them to GitHub via `git pull` (scentario 1)  or changing/adding files in the remote repo and sending them to your local computer via `git push`(scenario 2). The final outcome is that both remote and local repos end up with the same git commit history.\n",
    "\n",
    "- **Scenario 3** However, imagine that you working with collaborators and while you make some changes in your local repo, they also add changes on your remote.  If the changes are done on a different lines or different files (scenario 3), when you `git pull`, both changes will be \"merged\" into your document. \n",
    "\n",
    "- **Scenario 4** A merge conflict occurs when Git is unable to automatically reconcile differences between two file versions. This can happen, for example, if two people make changes to the same line in the file (scenario 4). When a merge conflict occurs, Git will prompt the user to manually resolve the conflict by editing the affected file to remove the conflicting changes and deciding which changes to keep. Once the conflict has been resolved and the file saved, the user can then commit the changes to complete the merge.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9262bb",
   "metadata": {},
   "source": [
    "\n",
    "----\n",
    "\n",
    "**Step 5.** Let's try scenario 3 ourselves! To try it:\n",
    "\n",
    "1. On the **remote** `recipe` folder modify a `README.md` file by adding the following text to the second line `line 2 changed remotely`, commit the changes. \n",
    "\n",
    "2. Using terminal, open `README.md` file on your **local** folder and add the new line `last line changed locally` at the very end of your file. Stage and commit the changes.\n",
    "<details><summary><b>Note:</b></summary>\n",
    "If you will try to perform this action using Jupyter Lab,when you open the file, Jupyter lab will immediately alert you that the remote contain changes that are not present in your local repo. Then, you will have an option either to pull the changes from the remote or continue without pulling.<br>\n",
    "<img src=\"images/Picture13.png\" width=70% ><br>\n",
    "To continue with this exercise using JupyterLab, just select press \"Continue without pulling\" (in real case scenario all you need is to do is Pull). \n",
    "</details><br>\n",
    "\n",
    "3. If you try the `git push` you will see that error message `failed to push some refs to 'https://github.com/yuliaUU/recipe.git'` and a hint ` Updates were rejected because the remote contains work that you do hint: not have locally` which basically tells you that you have two different commit histories (your local commit history in your local repo does not match the history in your remote). \n",
    "\n",
    "4. Now try to `git pull`- in terminal, you will see something similar to: <br><img src=\"images/Picture6.png\" width=50% >\n",
    "\n",
    "Note, If you are asked to enter a commit message, you can accept the default\n",
    "\n",
    "5. Since the changes were at different lines in the file, GitHub were able to figure out how to automatically merge them together (you may need to reopen the file to see the changes). Now your `README.md` file should have both new lines added to it (you can open the `README.md` file and check second and last lines). \n",
    "\n",
    "6. After you are happy with all the changes, push the merge changes to the remote repo\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf1382e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "    \n",
    "### Question 5\n",
    "    \n",
    "If you check the commit history, were the changes to the second and last lines were done simultaneously or git added each line in sequential order?\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "Try using either <code>git log</code> or <code>git log --oneline</code>\n",
    "</details><br>\n",
    "    \n",
    "A) Both lines were changed at the same time: you have a single commit message for both changes  \n",
    "B) First `line 2 changed remotely`, then `last line changed locally`  \n",
    "C) First `last line changed locally`, then `line 2 changed remotely`\n",
    "\n",
    " </div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b9bb5b98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'B'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q5 = \"B\"\n",
    "q5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c9429e50",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c36758a",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Step 6.** However, the issue arise when the same line in a file is changed in both places or when you change a file, for instance, in your local repo but delete this file in your remote and you try to git pull or push the changes. Now git is not sure which changes to keep and which to discard (or may be keep both?). \n",
    "\n",
    "<img src=\"images/Picture7.png\" width=50% >"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f7ef132",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Nobody wants to have merge conflicts! To understand the mechanism and prevent having one, why not create one on purpose? The scenario we will practice here, is similar to two users working on the same project, without knowing that they are changing the same file. \n",
    "\n",
    "1. Next, in you local repo, open your `README.md` file and add the following text as a **first and last** lines:<br> ```### This is a LOCAL change :)```<br>Stage your changes and commit them, but **DON'T PUSH.**\n",
    " \n",
    "2. Go to your remote repository on github.com and edit the **first and last lines** of the `README.md` by adding the following line<br>```### This is a REMOTE change :O```<br>Commit the changes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfcb215f",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "At this point, If you go to JupyterLab you will see that the file has been modified in the remote repository as you can see in the screenshot below:\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "<img src=\"images/Picture8.png\" width=40% >    \n",
    "</details>\n",
    "<br>\n",
    "You will also get a notification that the file has changed (if you open the file):\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "<img src=\"images/Picture13.png\" width=40% >    \n",
    "</details>\n",
    "<br>\n",
    "In addition, an orange dot will appear on both the \"pull\" and the \"push\" buttons. This indicates that there is new local changes to push AND new remote changes to pull at the same time). \n",
    "\n",
    "If you are working with the terminal, you can read similar information when reading this message as output from `git status`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2404da84",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 6a\n",
    "    \n",
    "How can you know that you have a merge conflict?\n",
    "\n",
    "A) You receive a message in JupyterLab  \n",
    "B) You can't push your changes - your updates are rejected  \n",
    "C) You receive a message about conflicting changes when pulling from the remote repository  \n",
    "D) The word MERGING will appear next to the name of the branch in your terminal window  \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "43435399",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ABCD'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q6a = \"ABCD\"\n",
    "q6a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "4f2d57a7",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q6a</pre></strong> passed! 💯</p>"
      ],
      "text/plain": [
       "q6a results: All test cases passed!"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q6a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90a0059",
   "metadata": {},
   "source": [
    "----\n",
    "\n",
    "**Step 7.** Press \"Pull\" button in a notification to try to merge our local and remote changes. We got a merge conflict! Next let's try to solve it.\n",
    "\n",
    "You can now see the `README.md` file appearing under the \"Conflicted\" tab. Click on the button to show the differences (conflicts). If your README file is too long also press on `(...)` symbol to see the entire document:\n",
    "\n",
    "<img src=\"images/Picture10.png\" width=100% >\n",
    "\n",
    "So let's solve the merge conflict! In Jupyter Lab IDE, all you need to do is to select which changes to implement from Current (ie local) or Incoming (ie remote). For our exercise, let's accept the following changes:\n",
    "\n",
    "1. Keep first line for changes done locally AND Keep last line for changes done remotely.\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "To select those changes just click on the arrows next to each line:\n",
    "<img src=\"images/Picture11.png\" width=100% >\n",
    "</details>\n",
    "\n",
    "2. Once you happy with changes (Note that you can also manually enter anything you like into Results section if you are neither happy with remote or local changes), press `Mark as resolved` button and commit the changes. Push the changes to the remote.\n",
    "\n",
    "<details><summary><b>Hint:</b></summary>\n",
    "<img src=\"images/Picture12.png\" width=100% >\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fcc79",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 7a\n",
    "    \n",
    "True or False? To solve a merge conflict, you have to select either the current or\n",
    "the incoming change.\n",
    "\n",
    "A) True  \n",
    "B) False  \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "ed3e548b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string \n",
    "q7a = \"B\"\n",
    "q7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "67a6a7c3",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7a</pre></strong> passed! ✨</p>"
      ],
      "text/plain": [
       "q7a results: All test cases passed!"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7a\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407eba99",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "    \n",
    "### Question 7b\n",
    "    \n",
    "Which of the following practices is the most important to help you\n",
    "avoid merge conflicts?\n",
    "\n",
    "A) Push changes to the remote repository daily before starting to work on your local changes.  \n",
    "B) Pull changes from the remote repository daily before starting to work on your local changes.  \n",
    "C) Stash changes using the terminal before pulling potentially new conflicting information from the remote repository..  \n",
    "D) Work only locally or only on the remote repository. \n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "9ee76675",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Your answer should be a string with all the letters of the options you think are correct, e.g. 'AB'\n",
    "q7b = \"b\"\n",
    "q7b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2693a33a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7b</pre></strong> passed! 🍀</p>"
      ],
      "text/plain": [
       "q7b results: All test cases passed!"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7388036d",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "### Question 7c\n",
    "    \n",
    "Paste the url to you recipe repo on GitHub in the cell below. This question will be manually graded after submission and there is no automatic test to run.\n",
    "\n",
    "Your link should look like something like this: https://github.com/YOUR-USER-NAME/recipe\n",
    "    \n",
    "You will be marked on the following:\n",
    "    \n",
    "- Correct URL link is provided\n",
    "- Resolved at least 1 merge conflict \n",
    "- Commit messages are comprehensive\n",
    "    \n",
    "</div>\n",
    "\n",
    "_Points:_ 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae3b3bb",
   "metadata": {},
   "source": [
    "_Type your answer here, replacing this text._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fec5be",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "----\n",
    "\n",
    "**Step 8 (Optional)** Aborting the merge conflict.\n",
    "\n",
    "Sometimes you get a merge conflict but you realized that you did some mistake / want to add more changes or you want to discuss the changes first with your collaborators. What to do in this case? You can abort the merge conflict and \"reset\" the state of your repo to the last committed state by just typing `git merge --abort` in your terminal. The repository looks then exactly as it was before the merge (check the `git status` and `git log --oneline`).\n",
    "\n",
    "To practice it, create a new merge conflict by modifying the same line on both remote and local files. Check `git status`. Then pull the changes from remote. Use `git merge --abort` and check the status again to explore the state of your repo (feel free to add more changes).  Resolve the conflict and push the changes to remote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e757cf",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\" style=\"color:black\">\n",
    "    \n",
    "**Restart and run all before submitting**\n",
    "    \n",
    "Before submitting,\n",
    "don't forget to run all cells in your notebook\n",
    "to make sure there are no errors\n",
    "and so that the TAs can see the output of all the cells properly.\n",
    "You can do this by clicking the ▶▶ button\n",
    "or going to `Kernel -> Restart Kernel and Run All Cells...` in the menu.\n",
    "This is not only important for this course,\n",
    "but a good habit you should get into before ever committing a notebook to GitHub,\n",
    "so that your collaborators can run it from top to bottom\n",
    "without issues.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d514f59b",
   "metadata": {},
   "source": [
    "------\n",
    "\n",
    "Assignment 4 completed, Congratulations! 🌈"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d55be8f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6be8e78a",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q0a results: All test cases passed!\n",
       "\n",
       "q0b results: All test cases passed!\n",
       "\n",
       "q0c results: All test cases passed!\n",
       "\n",
       "q0d results: All test cases passed!\n",
       "\n",
       "q0e results:\n",
       "    q0e - 1 message: Try again! You answer is not correct\n",
       "\n",
       "    q0e - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'c' == q0e.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q0e 0\n",
       "        Failed example:\n",
       "            assert 'c' == q0e.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q0e 0[0]>\", line 1, in <module>\n",
       "                assert 'c' == q0e.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q1a results: All test cases passed!\n",
       "\n",
       "q1b results:\n",
       "    q1b - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q1b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' in q1b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 0\n",
       "        Failed example:\n",
       "            assert 'a' in q1b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1b 0[0]>\", line 1, in <module>\n",
       "                assert 'a' in q1b.lower()\n",
       "                       ^^^^^^^^^^^^^^^^^^\n",
       "            AssertionError\n",
       "        Trying:\n",
       "            assert 'b' in q1b.lower()\n",
       "        Expecting nothing\n",
       "        ok\n",
       "\n",
       "    q1b - 2 message: At least one of the options you have selected is not correct\n",
       "\n",
       "    q1b - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'c' not in q1b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 1\n",
       "        Failed example:\n",
       "            assert 'c' not in q1b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1b 1[0]>\", line 1, in <module>\n",
       "                assert 'c' not in q1b.lower()\n",
       "                       ^^^^^^^^^^^^^^^^^^^^^^\n",
       "            AssertionError\n",
       "\n",
       "    q1b - 3 message: At least one of the options you have selected is not in correct order\n",
       "\n",
       "    q1b - 3 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert q1b.upper() == 'BA'\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q1b 2\n",
       "        Failed example:\n",
       "            assert q1b.upper() == 'BA'\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1b 2[0]>\", line 1, in <module>\n",
       "                assert q1b.upper() == 'BA'\n",
       "                       ^^^^^^^^^^^^^^^^^^^\n",
       "            AssertionError\n",
       "\n",
       "q1c results:\n",
       "    q1c - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q1c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' in q1c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q1c 0\n",
       "        Failed example:\n",
       "            assert 'b' in q1c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1c 0[0]>\", line 1, in <module>\n",
       "                assert 'b' in q1c.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'd' in q1c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q1c 0\n",
       "        Failed example:\n",
       "            assert 'd' in q1c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1c 0[1]>\", line 1, in <module>\n",
       "                assert 'd' in q1c.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "    q1c - 2 message: At least one of the options you have selected is not correct\n",
       "\n",
       "    q1c - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' not in q1c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q1c 1\n",
       "        Failed example:\n",
       "            assert 'a' not in q1c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1c 1[0]>\", line 1, in <module>\n",
       "                assert 'a' not in q1c.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'c' not in q1c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q1c 1\n",
       "        Failed example:\n",
       "            assert 'c' not in q1c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q1c 1[1]>\", line 1, in <module>\n",
       "                assert 'c' not in q1c.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q2a results:\n",
       "    q2a - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q2a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q2a 0\n",
       "        Failed example:\n",
       "            assert 'a' in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 0[0]>\", line 1, in <module>\n",
       "                assert 'a' in q2a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'd' in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q2a 0\n",
       "        Failed example:\n",
       "            assert 'd' in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 0[1]>\", line 1, in <module>\n",
       "                assert 'd' in q2a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'e' in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 3, in q2a 0\n",
       "        Failed example:\n",
       "            assert 'e' in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 0[2]>\", line 1, in <module>\n",
       "                assert 'e' in q2a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "    q2a - 2 message: At least one of the options you have selected is not correct\n",
       "\n",
       "    q2a - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' not in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q2a 1\n",
       "        Failed example:\n",
       "            assert 'b' not in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 1[0]>\", line 1, in <module>\n",
       "                assert 'b' not in q2a.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'c' not in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q2a 1\n",
       "        Failed example:\n",
       "            assert 'c' not in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 1[1]>\", line 1, in <module>\n",
       "                assert 'c' not in q2a.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'f' not in q2a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 3, in q2a 1\n",
       "        Failed example:\n",
       "            assert 'f' not in q2a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2a 1[2]>\", line 1, in <module>\n",
       "                assert 'f' not in q2a.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q2b results:\n",
       "    q2b - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q2b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' in q2b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q2b 0\n",
       "        Failed example:\n",
       "            assert 'b' in q2b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2b 0[0]>\", line 1, in <module>\n",
       "                assert 'b' in q2b.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'd' in q2b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q2b 0\n",
       "        Failed example:\n",
       "            assert 'd' in q2b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2b 0[1]>\", line 1, in <module>\n",
       "                assert 'd' in q2b.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "    q2b - 2 message: At least one of the options you have selected is not correct\n",
       "\n",
       "    q2b - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' not in q2b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q2b 1\n",
       "        Failed example:\n",
       "            assert 'a' not in q2b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2b 1[0]>\", line 1, in <module>\n",
       "                assert 'a' not in q2b.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'c' not in q2b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q2b 1\n",
       "        Failed example:\n",
       "            assert 'c' not in q2b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q2b 1[1]>\", line 1, in <module>\n",
       "                assert 'c' not in q2b.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q3a results:\n",
       "    q3a - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q3a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' == q3a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3a 0\n",
       "        Failed example:\n",
       "            assert 'b' == q3a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q3a 0[0]>\", line 1, in <module>\n",
       "                assert 'b' == q3a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q3b results:\n",
       "    q3b - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q3b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' == q3b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3b 0\n",
       "        Failed example:\n",
       "            assert 'b' == q3b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q3b 0[0]>\", line 1, in <module>\n",
       "                assert 'b' == q3b.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q3c results:\n",
       "    q3c - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q3c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' == q3c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3c 0\n",
       "        Failed example:\n",
       "            assert 'a' == q3c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q3c 0[0]>\", line 1, in <module>\n",
       "                assert 'a' == q3c.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q4a results:\n",
       "    q4a - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q4a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' in q4a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q4a 0\n",
       "        Failed example:\n",
       "            assert 'a' in q4a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4a 0[0]>\", line 1, in <module>\n",
       "                assert 'a' in q4a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'b' in q4a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q4a 0\n",
       "        Failed example:\n",
       "            assert 'b' in q4a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4a 0[1]>\", line 1, in <module>\n",
       "                assert 'b' in q4a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "    q4a - 2 message: At least one of the options you have selected is not correct\n",
       "\n",
       "    q4a - 2 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'c' not in q4a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q4a 1\n",
       "        Failed example:\n",
       "            assert 'c' not in q4a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4a 1[0]>\", line 1, in <module>\n",
       "                assert 'c' not in q4a.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'd' not in q4a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q4a 1\n",
       "        Failed example:\n",
       "            assert 'd' not in q4a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4a 1[1]>\", line 1, in <module>\n",
       "                assert 'd' not in q4a.lower()\n",
       "                                  ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q4b results:\n",
       "    q4b - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q4b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' == q4b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q4b 0\n",
       "        Failed example:\n",
       "            assert 'a' == q4b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4b 0[0]>\", line 1, in <module>\n",
       "                assert 'a' == q4b.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q4c results:\n",
       "    q4c - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q4c - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'd' == q4c.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q4c 0\n",
       "        Failed example:\n",
       "            assert 'd' == q4c.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q4c 0[0]>\", line 1, in <module>\n",
       "                assert 'd' == q4c.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q5 results:\n",
       "    q5 - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q5 - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' == q5.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q5 0\n",
       "        Failed example:\n",
       "            assert 'b' == q5.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q5 0[0]>\", line 1, in <module>\n",
       "                assert 'b' == q5.lower()\n",
       "                              ^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q6a results:\n",
       "    q6a - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q6a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'a' in q6a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q6a 0\n",
       "        Failed example:\n",
       "            assert 'a' in q6a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q6a 0[0]>\", line 1, in <module>\n",
       "                assert 'a' in q6a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'b' in q6a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 2, in q6a 0\n",
       "        Failed example:\n",
       "            assert 'b' in q6a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q6a 0[1]>\", line 1, in <module>\n",
       "                assert 'b' in q6a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'c' in q6a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 3, in q6a 0\n",
       "        Failed example:\n",
       "            assert 'c' in q6a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q6a 0[2]>\", line 1, in <module>\n",
       "                assert 'c' in q6a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "        Trying:\n",
       "            assert 'd' in q6a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 4, in q6a 0\n",
       "        Failed example:\n",
       "            assert 'd' in q6a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q6a 0[3]>\", line 1, in <module>\n",
       "                assert 'd' in q6a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q7a results:\n",
       "    q7a - 1 message: Your answer is incorrect or you are missing one of the correct answers\n",
       "\n",
       "    q7a - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' == q7a.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q7a 0\n",
       "        Failed example:\n",
       "            assert 'b' == q7a.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q7a 0[0]>\", line 1, in <module>\n",
       "                assert 'b' == q7a.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'\n",
       "\n",
       "q7b results:\n",
       "    q7b - 1 message: You are missing one of the correct answers\n",
       "\n",
       "    q7b - 1 result:\n",
       "        ❌ Test case failed\n",
       "        Trying:\n",
       "            assert 'b' == q7b.lower()\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q7b 0\n",
       "        Failed example:\n",
       "            assert 'b' == q7b.lower()\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/miniconda3/lib/python3.13/doctest.py\", line 1395, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "                ~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "                             compileflags, True), test.globs)\n",
       "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
       "              File \"<doctest q7b 0[0]>\", line 1, in <module>\n",
       "                assert 'b' == q7b.lower()\n",
       "                              ^^^^^^^^^\n",
       "            AttributeError: 'ellipsis' object has no attribute 'lower'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  },
  "otter": {
   "OK_FORMAT": true,
   "tests": {
    "q0a": {
     "name": "q0a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'c' == q0a.lower()\n>>> \n",
         "failure_message": "Try again! You answer is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0b": {
     "name": "q0b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' == q0b.lower()\n",
         "failure_message": "Try again! You answer is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0c": {
     "name": "q0c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q0c.lower()\n",
         "failure_message": "Try again! You answer is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0d": {
     "name": "q0d",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' == q0d.lower()\n",
         "failure_message": "Try again! You answer is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q0e": {
     "name": "q0e",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'c' == q0e.lower()\n",
         "failure_message": "Try again! You answer is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1a": {
     "name": "q1a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' in q1a.lower()\n>>> assert 'b' in q1a.lower()\n>>> assert 'c' in q1a.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'd' not in q1a.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1b": {
     "name": "q1b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' in q1b.lower()\n>>> assert 'b' in q1b.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'c' not in q1b.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert q1b.upper() == 'BA'\n",
         "failure_message": "At least one of the options you have selected is not in correct order",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q1c": {
     "name": "q1c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' in q1c.lower()\n>>> assert 'd' in q1c.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'a' not in q1c.lower()\n>>> assert 'c' not in q1c.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2a": {
     "name": "q2a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' in q2a.lower()\n>>> assert 'd' in q2a.lower()\n>>> assert 'e' in q2a.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'b' not in q2a.lower()\n>>> assert 'c' not in q2a.lower()\n>>> assert 'f' not in q2a.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2b": {
     "name": "q2b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' in q2b.lower()\n>>> assert 'd' in q2b.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'a' not in q2b.lower()\n>>> assert 'c' not in q2b.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3a": {
     "name": "q3a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q3a.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3b": {
     "name": "q3b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q3b.lower()\n>>> \n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3c": {
     "name": "q3c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' == q3c.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4a": {
     "name": "q4a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' in q4a.lower()\n>>> assert 'b' in q4a.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> assert 'c' not in q4a.lower()\n>>> assert 'd' not in q4a.lower()\n",
         "failure_message": "At least one of the options you have selected is not correct",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4b": {
     "name": "q4b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' == q4b.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4c": {
     "name": "q4c",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'd' == q4c.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q5.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q6a": {
     "name": "q6a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'a' in q6a.lower()\n>>> assert 'b' in q6a.lower()\n>>> assert 'c' in q6a.lower()\n>>> assert 'd' in q6a.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7a": {
     "name": "q7a",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q7a.lower()\n",
         "failure_message": "Your answer is incorrect or you are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7b": {
     "name": "q7b",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert 'b' == q7b.lower()\n",
         "failure_message": "You are missing one of the correct answers",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
